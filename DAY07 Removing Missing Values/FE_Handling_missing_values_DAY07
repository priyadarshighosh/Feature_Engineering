{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"1RO_zr_tQ3BNsXnC3GhDtgR0KuMPaUI7_","timestamp":1726059232666},{"file_id":"1ahyTCXn-3LXAXyJkvqVyfqNlQ4Eex31M","timestamp":1726057833443},{"file_id":"1sUMvMIQRQaOZ9J_H8sHaj9zr3VH34vdK","timestamp":1725989843585}],"authorship_tag":"ABX9TyPiLXY0w9poFKs5GWggpUlc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HANDLING MISSING VALUES\n","\n","# Implementation"],"metadata":{"id":"buV9E0bf-37g"}},{"cell_type":"markdown","source":["IMPORTING THE DATA SCIENCE LIBRARIES"],"metadata":{"id":"HNvHInaq_BMJ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eum2WGOnBeeL"},"outputs":[],"source":["\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import time"]},{"cell_type":"markdown","source":["Importing the ML / Scikit learn EVERYTHING"],"metadata":{"id":"egI1aKHM_G4g"}},{"cell_type":"code","source":["\n","from sklearn.model_selection import train_test_split               #for splitting the data into test and training data\n","from sklearn.compose import ColumnTransformer                       #for transforming the columns\n","from sklearn.impute import SimpleImputer                             #for imputing the missing values\n","from sklearn.preprocessing import OneHotEncoder                      #one hot encoding\n","from sklearn.preprocessing import MinMaxScaler                        #standard scaling\n","from sklearn.pipeline import Pipeline,make_pipeline                    #here we wont use pipelines\n","from sklearn.feature_selection import SelectKBest,chi2                 #feature selection                     #standard scaling\n","from sklearn.tree import DecisionTreeClassifier"],"metadata":{"id":"v-A2uAybzaKX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset Preprocessing and CLEANING"],"metadata":{"id":"ADdQQGes_Sdp"}},{"cell_type":"code","source":["\n","from google.colab import files    # we are importing the file from the device\n","uploaded = files.upload()"],"metadata":{"id":"GynCwG0YCHzg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('data_science_job.csv')\n","df.head()"],"metadata":{"id":"5btQS0GnzulN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape   #checking the shape of the data"],"metadata":{"id":"uYYUMmaXDB6L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()  #checking the info of the data"],"metadata":{"id":"CTeAHSkCDMTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe()  #checking the statistical description of the data"],"metadata":{"id":"1Ik4DxWTDONQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Stats about Missing Values"],"metadata":{"id":"7oB9_9L1rcdm"}},{"cell_type":"code","source":["df.isnull().sum() #checking the number of  missing values"],"metadata":{"id":"PK1aD0rnrQ4W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["What is the percentage of the Missing Values"],"metadata":{"id":"PcNZnpNYrn--"}},{"cell_type":"code","source":["df.isnull().mean()*100          #percentage of missing values"],"metadata":{"id":"f7OaY8h9rs96"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["How we should THINK THAT IN WHICH COLUMN SHOULD CCA be applied -- the columns that has less than 5 perc of the data Missing\n","\n","ie - city_development,\n","     enrolled_university,\n","     education_level,\n","     experience,\n","     training_hours ."],"metadata":{"id":"iG1VHjussJ5G"}},{"cell_type":"markdown","source":["# REMOVING ROWS WHERE MISSING PERCENTAGE IS LESS THAN 5 PERC"],"metadata":{"id":"pLYV6cYCs2z8"}},{"cell_type":"code","source":["cols = [var for var in df.columns if df[var].isnull().mean()<0.05 and df[var].isnull().mean()>0]\n","cols                       # this is how we get the columns with less than 5 perc missing values\n",""],"metadata":{"id":"YA8WDQg4s_XM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We getting the values of those 5 columns"],"metadata":{"id":"tZRjYqtMuAdk"}},{"cell_type":"code","source":["df[cols].sample(5)"],"metadata":{"id":"7ZaOhC0ztgau"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now we will see if we drop the rows with any null values , then how much percentage of the past data will be left with us"],"metadata":{"id":"dMFkXTqIuGJx"}},{"cell_type":"code","source":["len(df[cols].dropna())/len(df)"],"metadata":{"id":"_Ue7vaFfuWgb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10 perc of the Data is not much thats why we will drop all those rows"],"metadata":{"id":"AxjiOfHwubxM"}},{"cell_type":"code","source":["new_df = df[cols].dropna()\n","df[cols].shape,new_df.shape    #  previously it had 19 k rows now it has 17 k rows in those 5 columns"],"metadata":{"id":"592Msn5Duoi2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# COMPARING GRAPHS FOR THE NUMERICAL COLUMNS"],"metadata":{"id":"h9hFyTMfybwP"}},{"cell_type":"markdown","source":["DRAWING THE GRAPHS"],"metadata":{"id":"XOuF0Wq-v0dv"}},{"cell_type":"code","source":["new_df.hist(bins=50 , density=True , figsize=(12,12))\n","plt.show"],"metadata":{"id":"0qiqdoXqv4Em"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","#original data\n","df['training_hours'].hist(bins=50 , density=True , alpha=0.5)\n","\n","#data after cca, the argument alpha makes the color transparent so we can see the overlay of the 2 distributions\n","\n","new_df['training_hours'].hist(bins=50 , density=True , alpha=0.5)"],"metadata":{"id":"YmzFpmBNwYWr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["even after removig the missing values the distribution is same"],"metadata":{"id":"LITGQUPhxREx"}},{"cell_type":"code","source":["fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","#original data\n","df['city_development_index'].hist(bins=50 , density=True , alpha=0.5)\n","\n","#data after cca, the argument alpha makes the color transparent so we can see the overlay of the 2 distributions\n","\n","new_df['city_development_index'].hist(bins=50 , density=True , alpha=0.5)"],"metadata":{"id":"kXC7iN1uxnA5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure()\n","ax = fig.add_subplot(111)\n","\n","#original data\n","df['experience'].hist(bins=50 , density=True , alpha=0.5)\n","\n","#data after cca, the argument alpha makes the color transparent so we can see the overlay of the 2 distributions\n","\n","new_df['experience'].hist(bins=50 , density=True , alpha=0.5)"],"metadata":{"id":"vCyA1Oicxn50"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" when we compare the blue graphs with the brown graphs we can see that the distribution is same\n","\n","  values are at MCAR  - Missing Completly at random\n","  So we apply CCA"],"metadata":{"id":"JeGesdCnx-5G"}},{"cell_type":"markdown","source":["#  Comparing Graphs for the Categorical Columns"],"metadata":{"id":"zkgh9_J9ymrK"}},{"cell_type":"code","source":["df['education_level'].value_counts()  #ratios should be same"],"metadata":{"id":"feiD-rQ1yynq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['enrolled_university'].value_counts() #ratios should be same"],"metadata":{"id":"xGorzGRzzGDj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["WE have to see that the ratio in which these categories remain same"],"metadata":{"id":"Ravzp6qEzVAl"}},{"cell_type":"markdown","source":["# Ratio Comparison of the categorical columns"],"metadata":{"id":"Y6pUV92X8sWV"}},{"cell_type":"code","source":["temp = pd.concat([\n","\n","    #percentage before rows have been removed ( original column data)\n","    df['education_level'].value_counts()/len(df),\n","\n","    #percentage after rows have been removed\n","    new_df['education_level'].value_counts()/len(new_df)\n","],axis=1)\n","\n","#add column names\n","temp.columns = ['original','after elimination']\n","\n","temp"],"metadata":{"id":"BKpbJDXg8xJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp = pd.concat([\n","\n","    #percentage before rows have been removed ( original column data)\n","    df['enrolled_university'].value_counts()/len(df),\n","\n","    #percentage after rows have been removed\n","    new_df['enrolled_university'].value_counts()/len(new_df)\n","],axis=1)\n","\n","#add column names\n","temp.columns = ['original','after elimination']\n","\n","temp"],"metadata":{"id":"EPqAojqp9edw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can see that the 2 categorical columns the ratios remain same even after removal of columns , so the columns in MCRA , so we perform the removal of rows"],"metadata":{"id":"V7WftzK_-KoZ"}}]}